{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPu5BYzKwQ3GsYYoApSVHHh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parthava-adabala/learning/blob/main/04_Pytorch_custom_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0n3kbLDr9ny9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "nI2lC0Fu9_pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "v-eiYxN8-s1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "  print(f\"Did not find {image_path} directory, creating one...\")\n",
        "  image_path.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "nJbeTcsB-21c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "  request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "  print(\"Downlaoding pizza, steak, sushi data...\")\n",
        "  f.write(request.content)\n",
        "\n",
        "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "  print(\"Unzipping pizza, steak, sushi data...\")\n",
        "  zip_ref.extractall(image_path)"
      ],
      "metadata": {
        "id": "-o4Nfk9Q_tSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation and data exploration"
      ],
      "metadata": {
        "id": "7o5CvoT2AkSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def walk_through_dir(dir_path):\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
        "walk_through_dir(image_path)"
      ],
      "metadata": {
        "id": "VpfiBWp1GKBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = image_path/\"train\"\n",
        "test_dir = image_path/\"test\"\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "id": "_GYnfCDQGpBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# visualizing and image"
      ],
      "metadata": {
        "id": "WCzV1Rc3IK1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
        "\n",
        "random_image_path = random.choice(image_path_list)\n",
        "print(random_image_path)\n",
        "\n",
        "image_class = random_image_path.parent.stem\n",
        "print(image_class)\n",
        "\n",
        "image = Image.open(random_image_path)\n",
        "print(image.height, image.width)\n",
        "image"
      ],
      "metadata": {
        "id": "1VW5teeKI6Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_as_array = np.asarray(image)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.imshow(image_as_array)\n",
        "plt.title(f\"Image class: {image_class}\")\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "uXSFJIZJJVw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transforming data"
      ],
      "metadata": {
        "id": "7ofP_0cTJnmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets"
      ],
      "metadata": {
        "id": "7MvfhPTtLQaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transform = transforms.Compose([transforms.Resize(size=(64,64)),\n",
        "                                     transforms.RandomHorizontalFlip(p = 0.5),\n",
        "                                     transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "EyiVraLHL0yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transform(image)"
      ],
      "metadata": {
        "id": "V3vvN_1DNrqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_transformed_image(image_path, transform, n=3, seed=42):\n",
        "  if seed:\n",
        "    random.seed(seed)\n",
        "  random_image_path = random.sample(image_path, k=n)\n",
        "  for image_path in random_image_path:\n",
        "    with Image.open(image_path) as f:\n",
        "      fig, ax = plt.subplots(nrows=1, ncols=2)\n",
        "      ax[0].imshow(f)\n",
        "      ax[0].set_title(f\"Original \\nSize: {f.size}\")\n",
        "      ax[0].axis(\"off\")\n",
        "\n",
        "      transformed_image = transform(f).permute(1,2,0)\n",
        "      ax[1].imshow(transformed_image)\n",
        "      ax[1].set_title(f\"Transformed \\nSize: {transformed_image.shape}\")\n",
        "      ax[1].axis(\"off\")\n",
        "      fig.suptitle(f\"Class: {image_path.parent.stem}\", fontsize=30)\n",
        "plot_transformed_image(image_path=image_path_list, transform = data_transform, n=3, seed=42)"
      ],
      "metadata": {
        "id": "mzXOUjePgdWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading image data using image folder"
      ],
      "metadata": {
        "id": "GKwC6xcUiVFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "train_data = datasets.ImageFolder(root=train_dir, transform=data_transform, target_transform=None)\n",
        "test_data = datasets.ImageFolder(root=test_dir, transform=data_transform)\n",
        "train_data, test_data"
      ],
      "metadata": {
        "id": "tgjZPPK8jM1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "KBnCDKx-juFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_dict = train_data.class_to_idx\n",
        "class_dict"
      ],
      "metadata": {
        "id": "5fMEDv8Qj3ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "p80x-IxnkNLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.samples[0]"
      ],
      "metadata": {
        "id": "E4kjCCwZkZ4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = train_data[0][0], train_data[0][1]\n",
        "img, label, class_names[label]"
      ],
      "metadata": {
        "id": "5Fr6_1yRkdec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_permute = img.permute(1,2,0)\n",
        "print(img_permute.shape, img.shape)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.imshow(img_permute)\n",
        "plt.title(f\"Class: {class_names[label]}\")\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "mY5AD96nkvgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data loaders"
      ],
      "metadata": {
        "id": "zaAoXo_9lCmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE=1\n",
        "train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=1)\n",
        "test_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "3Dsrj4GPf9G2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader), len(test_dataloader)"
      ],
      "metadata": {
        "id": "HAcNVQVpggfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = next(iter(train_dataloader))\n",
        "print(img.shape, label.shape)"
      ],
      "metadata": {
        "id": "GgkD4vQZguPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Image data with a custom dataset"
      ],
      "metadata": {
        "id": "kADBZiN8g0_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import torch\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from typing import Tuple, Dict, List"
      ],
      "metadata": {
        "id": "T2eehi9LmRLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.classes, train_data.class_to_idx"
      ],
      "metadata": {
        "id": "b2yLkCrImSvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a helper function to get class names\n",
        "\n",
        "target_directory = train_dir\n",
        "class_names_found = sorted([entry.name for entry in os.scandir(target_directory) if entry.is_dir()])\n",
        "class_names_found"
      ],
      "metadata": {
        "id": "GDKYmC26mfl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(os.scandir(target_directory))"
      ],
      "metadata": {
        "id": "2kGqgUbTnIRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_classes(target_directory: str) -> Tuple[List[str],Dict[str, int]]:\n",
        "  classes = sorted([entry.name for entry in os.scandir(target_directory) if entry.is_dir()])\n",
        "  if not classes:\n",
        "    raise FileNotFoundError(f\"Couldn't find any classes in {target_directory}\")\n",
        "\n",
        "  class_to_idx = {cls_name: idx for idx, cls_name in enumerate(classes)}\n",
        "  return classes, class_to_idx"
      ],
      "metadata": {
        "id": "Ctv5pGA_npSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_classes(target_directory)"
      ],
      "metadata": {
        "id": "n7sw3ZbdoaM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create custom dataset to replicate image folder\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ImageFolderCustom(Dataset):\n",
        "  def __init__(self, target_dir: str, transform=None) -> None:\n",
        "\n",
        "    self.paths = list(pathlib.Path(target_dir).glob(\"*/*.jpg\"))\n",
        "    self.transform = transform\n",
        "    self.classes, self.class_to_idx = find_classes(target_dir)\n",
        "\n",
        "  def load_image(self, index: int) -> Image.Image:\n",
        "    image_path = self.paths[index]\n",
        "    return Image.open(image_path)\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return len(self.paths)\n",
        "\n",
        "  def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
        "    image = self.load_image(index)\n",
        "    class_name = self.paths[index].parent.name\n",
        "    class_idx = self.class_to_idx[class_name]\n",
        "\n",
        "    if self.transform:\n",
        "      return self.transform(image), class_idx\n",
        "    else:\n",
        "      return image, class_idx"
      ],
      "metadata": {
        "id": "gDE9DI2jo8Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a transform\n",
        "from torchvision import transforms\n",
        "train_transforms = transforms.Compose([transforms.Resize(size=(64,64)),\n",
        "                                        transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                        transforms.ToTensor()])\n",
        "test_transforms = transforms.Compose([transforms.Resize(size=(64,64)),\n",
        "                                       transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "vnWh2nN0rqYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_custom = ImageFolderCustom(target_dir=train_dir, transform=train_transforms)\n",
        "test_data_custom = ImageFolderCustom(target_dir=test_dir, transform=test_transforms)\n",
        "train_data_custom, test_data_custom"
      ],
      "metadata": {
        "id": "opHBAO5PsbNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data_custom), len(test_data_custom)"
      ],
      "metadata": {
        "id": "4--J2iRktNdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_data), len(test_data_custom)"
      ],
      "metadata": {
        "id": "hAoiI52OtTqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_custom.classes"
      ],
      "metadata": {
        "id": "hQ9wWT5xtaMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_custom.class_to_idx"
      ],
      "metadata": {
        "id": "8TWwO7v_tmN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check for quality\n",
        "print(train_data.classes == train_data_custom.classes)\n",
        "print(train_data.class_to_idx == train_data_custom.class_to_idx)"
      ],
      "metadata": {
        "id": "INQdexTFt-QR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a function to display random images\n",
        "import random\n",
        "\n",
        "def display_random_images(dataset: torch.utils.data.Dataset, classes:List[str]=None, n:int=10, display_shape: bool = True, seed:int = None):\n",
        "  if n>10:\n",
        "    n=10\n",
        "    display_shape = False\n",
        "    print(f\"For display purposes, n shouldn't be greater than 10, setting to 10.\")\n",
        "\n",
        "  if seed:\n",
        "    random.seed(seed)\n",
        "  random_samples_idx = random.sample(range(len(dataset)), k=n)\n",
        "\n",
        "  plt.figure(figsize=(16,8))\n",
        "\n",
        "\n",
        "  for i, targ_sample in enumerate(random_samples_idx):\n",
        "    targ_img, targ_label = dataset[targ_sample][0], dataset[targ_sample][1]\n",
        "    targ_img_adjusted = targ_img.permute(1,2,0)\n",
        "    plt.subplot(1,n,i+1)\n",
        "    plt.imshow(targ_img_adjusted)\n",
        "    if classes:\n",
        "      plt.title(f\"class: {classes[targ_label]}\")\n",
        "      if display_shape:\n",
        "        plt.title(f\"class: {classes[targ_label]} \\n shape: {targ_img_adjusted.shape}\")"
      ],
      "metadata": {
        "id": "mUT8bVhQuIMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_random_images(dataset=train_data, classes=train_data.classes, n=5, seed=42)"
      ],
      "metadata": {
        "id": "tC7fkDPku0yH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_random_images(dataset=train_data_custom, classes=train_data_custom.classes, n=5, seed=42)"
      ],
      "metadata": {
        "id": "1qsETy-a4Yfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn loaded images into dataloader\n",
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 32\n",
        "train_dataloader_custom = DataLoader(dataset=train_data_custom, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "test_dataloader_custom = DataLoader(dataset=test_data_custom, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "train_dataloader_custom, test_dataloader_custom"
      ],
      "metadata": {
        "id": "ZcR3C2Zf4quh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_custom, label_custom = next(iter(train_dataloader_custom))\n",
        "print(image_custom.shape, label_custom.shape)"
      ],
      "metadata": {
        "id": "Y_daQ6B75E31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Other forms of transforms (data augmentation)\n",
        "from torchvision import transforms\n",
        "train_transforms = transforms.Compose([transforms.Resize(size=(64,64)),\n",
        "                                            transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
        "                                        transforms.ToTensor()])\n",
        "test_transforms = transforms.Compose([transforms.Resize(size=(64,64)),\n",
        "                                       transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "cQqTwMqV5Zq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
        "image_path_list[:10]"
      ],
      "metadata": {
        "id": "lS3T2QzM7RAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_transformed_image(image_path=image_path_list, transform = train_transforms, n=3, seed=42)"
      ],
      "metadata": {
        "id": "17RXnMk-7bsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 0 Tiny VGG without data augmentation"
      ],
      "metadata": {
        "id": "pcHdfZ_670Zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_transform = transforms.Compose([transforms.Resize(size=(64,64)),\n",
        "                                        transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "45SOAoy-8iLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "train_data_simple = datasets.ImageFolder(root=train_dir, transform=simple_transform, target_transform=None)\n",
        "test_data_simple = datasets.ImageFolder(root=test_dir, transform=simple_transform)\n",
        "\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE=1\n",
        "NUM_WORKERS=os.cpu_count()\n",
        "train_dataloader_simple = DataLoader(dataset=train_data_simple, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "test_dataloader_simple = DataLoader(dataset=test_data_simple, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "train_dataloader_simple, test_dataloader_simple"
      ],
      "metadata": {
        "id": "czGZMuw28rrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_WORKERS"
      ],
      "metadata": {
        "id": "g96JvU6w9X-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TinyVGG(nn.Module):\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*16*16, out_features=output_shape)\n",
        "    )\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    x = self.conv_block_1(x)\n",
        "    x = self.conv_block_2(x)\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "7wYfX5ih9afM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model_0 = TinyVGG(input_shape=3, hidden_units=10, output_shape=len(train_data_simple.classes)).to(device)\n",
        "model_0"
      ],
      "metadata": {
        "id": "MvO3dxvY-8AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try a single image\n",
        "image_batch, label_batch = next(iter(train_dataloader_simple))\n",
        "image_batch.shape, label_batch.shape"
      ],
      "metadata": {
        "id": "V2s9iFCk_qy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0(image_batch)"
      ],
      "metadata": {
        "id": "TAjpxKbqAUzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use torch info\n",
        "try:\n",
        "  from torchinfo import summary\n",
        "except:\n",
        "  print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "  !pip install -q torchinfo\n",
        "  from torchinfo import summary\n",
        "\n",
        "summary(model=model_0, input_size=(1, 3, 64, 64))"
      ],
      "metadata": {
        "id": "Jv90GGMtApJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train and test loops"
      ],
      "metadata": {
        "id": "jThgawTKBRXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module, optimizer: torch.optim.Optimizer, device: torch.device):\n",
        "  model.train()\n",
        "  train_loss, train_acc = 0, 0\n",
        "  for batch, (X,y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    y_pred = model(X)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss.item()\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "    train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "  train_loss /= len(dataloader)\n",
        "  train_acc /= len(dataloader)\n",
        "  return train_loss, train_acc"
      ],
      "metadata": {
        "id": "9HLM3VAGCU0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model: torch.nn.Module, dataloader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module, device: torch.device):\n",
        "  model.eval()\n",
        "  test_loss, test_acc = 0, 0\n",
        "  with torch.inference_mode():\n",
        "    for batch, (X,y) in enumerate(dataloader):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      test_pred_logits = model(X)\n",
        "      loss = loss_fn(test_pred_logits, y)\n",
        "      test_loss += loss.item()\n",
        "      test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "      test_acc+= ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "  test_loss /= len(dataloader)\n",
        "  test_acc /= len(dataloader)\n",
        "  return test_loss, test_acc"
      ],
      "metadata": {
        "id": "FMooO4cjDGd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "def train(model: torch.nn.Module, train_dataloader: DataLoader, test_dataloader: DataLoader, optimizer: torch.optim.Optimizer, loss_fn: torch.nn.Module = nn.CrossEntropyLoss(), epochs: int=5, device: torch.device=device):\n",
        "  results = {\"train_loss\": [], \"train_acc\": [], \"test_loss\": [], \"test_acc\": []}\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss, train_acc = train_step(model=model, dataloader=train_dataloader, loss_fn=loss_fn, optimizer=optimizer, device=device)\n",
        "    test_loss, test_acc = test_step(model=model, dataloader=test_dataloader, loss_fn=loss_fn, device=device)\n",
        "    print(f\"Epoch: {epoch} | train_loss: {train_loss:.4f} | train_acc: {train_acc:.4f} | test_loss: {test_loss:.4f} | test_acc: {test_acc:.4f}\")\n",
        "    results[\"train_loss\"].append(train_loss)\n",
        "    results[\"train_acc\"].append(train_acc)\n",
        "    results[\"test_loss\"].append(test_loss)\n",
        "    results[\"test_acc\"].append(test_acc)\n",
        "  return results"
      ],
      "metadata": {
        "id": "gwJEZjSLEz_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train and evaluate model 0\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "model_0 = TinyVGG(input_shape=3, hidden_units=10, output_shape=len(train_data.classes))\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.001)\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "model_0_results = train(model=model_0, train_dataloader=train_dataloader_simple, test_dataloader=test_dataloader_simple, optimizer=optimizer, loss_fn=loss_fn, epochs=NUM_EPOCHS)\n",
        "\n",
        "end_time = timer()\n",
        "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
      ],
      "metadata": {
        "id": "YDAs97l0F9HK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_results.keys()"
      ],
      "metadata": {
        "id": "mOOfhAZeHe99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_curves(results: Dict[str, List[float]]):\n",
        "  loss = results[\"train_loss\"]\n",
        "  test_loss = results[\"test_loss\"]\n",
        "  accuracy = results[\"train_acc\"]\n",
        "  test_accuracy = results[\"test_acc\"]\n",
        "  epochs = range(len(results[\"train_loss\"]))\n",
        "  plt.figure(figsize=(15,7))\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.plot(epochs, loss, label=\"train_loss\")\n",
        "  plt.plot(epochs, test_loss, label=\"test_loss\")\n",
        "  plt.title(\"Loss\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.legend()\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(epochs, accuracy, label=\"train_accuracy\")\n",
        "  plt.plot(epochs, test_accuracy, label=\"test_accuracy\")\n",
        "  plt.title(\"Accuracy\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "m2h-QLL7IUP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(model_0_results)"
      ],
      "metadata": {
        "id": "Yr7Cip7-I48H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create model 1 with data augmentation\n",
        "from torchvision import transforms\n",
        "train_transforms_trivial = transforms.Compose([transforms.Resize(size=(64,64)),\n",
        "                                        transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
        "                                        transforms.ToTensor()])\n",
        "test_transforms_trivial = transforms.Compose([transforms.Resize(size=(64,64)),\n",
        "                                       transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "Z8x0KClvI7Yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_augmented = ImageFolderCustom(target_dir=train_dir, transform=train_transforms_trivial)\n",
        "test_data_simple = ImageFolderCustom(target_dir=test_dir, transform=test_transforms)"
      ],
      "metadata": {
        "id": "mfdwk0irLgHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE=32\n",
        "NUM_WORKERS=os.cpu_count()\n",
        "\n",
        "torch.manual_seed(42)\n",
        "train_dataloader_augmented = DataLoader(dataset=train_data_augmented, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "test_dataloader_simple = DataLoader(dataset=test_data_simple, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "train_dataloader_augmented, test_dataloader_simple"
      ],
      "metadata": {
        "id": "Fvw-v2EAMDVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# construct and train model 1\n",
        "torch.manual_seed(42)\n",
        "\n",
        "model_1 = TinyVGG(input_shape=3, hidden_units=10, output_shape=len(train_data_augmented.classes)).to(device)\n",
        "model_1"
      ],
      "metadata": {
        "id": "Bbu9C6NRMpDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "NUM_EPOCHS=5\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model_1.parameters(), lr=0.001)\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "model_1_results = train(model=model_1, train_dataloader=train_dataloader_augmented, test_dataloader=test_dataloader_simple, optimizer=optimizer, loss_fn=loss_fn, epochs=NUM_EPOCHS)\n",
        "\n",
        "end_time = timer()\n",
        "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
      ],
      "metadata": {
        "id": "Z8mk2z3-OHz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss curves of model 1 results\n",
        "plot_loss_curves(model_1_results)"
      ],
      "metadata": {
        "id": "inuo8jTSOftS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compare model results\n",
        "import pandas as pd\n",
        "model_0_results_df = pd.DataFrame(model_0_results)\n",
        "model_1_results_df = pd.DataFrame(model_1_results)\n",
        "model_0_results_df, model_1_results_df"
      ],
      "metadata": {
        "id": "o3XdSTi5O4Tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "epochs = range(len(model_0_results_df))\n",
        "\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(epochs, model_0_results_df[\"train_loss\"], label=\"model_0\")\n",
        "plt.plot(epochs, model_1_results_df[\"train_loss\"], label=\"model_1\")\n",
        "plt.title(\"Train loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(epochs, model_0_results_df[\"test_loss\"], label=\"model_0\")\n",
        "plt.plot(epochs, model_1_results_df[\"test_loss\"], label=\"model_1\")\n",
        "plt.title(\"Test loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2,2,3)\n",
        "plt.plot(epochs, model_0_results_df[\"train_acc\"], label=\"model_0\")\n",
        "plt.plot(epochs, model_1_results_df[\"train_acc\"], label=\"model_1\")\n",
        "plt.title(\"Train accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2,2,4)\n",
        "plt.plot(epochs, model_0_results_df[\"test_acc\"], label=\"model_0\")\n",
        "plt.plot(epochs, model_1_results_df[\"test_acc\"], label=\"model_1\")\n",
        "plt.title(\"Test accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "RfFcs4EWPWOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making a prediction on a custom image\n",
        "import requests\n",
        "\n",
        "custom_image_path = data_path / \"04-pizza-dad.jpeg\"\n",
        "\n",
        "if not custom_image_path.is_file():\n",
        "  with open(custom_image_path, \"wb\") as f:\n",
        "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/images/04-pizza-dad.jpeg\")\n",
        "    f.write(request.content)\n",
        "else:\n",
        "  print(f\"{custom_image_path} already exists\")"
      ],
      "metadata": {
        "id": "_6rnl6QPPYj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_image_path"
      ],
      "metadata": {
        "id": "IYW754KjTJgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load custom image\n",
        "import torchvision\n",
        "custom_image_uint8 = torchvision.io.read_image(str(custom_image_path))\n",
        "custom_image_uint8, custom_image_uint8.shape, custom_image_uint8.dtype"
      ],
      "metadata": {
        "id": "x9ndRcFNQyn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(custom_image_uint8.permute(1,2,0))"
      ],
      "metadata": {
        "id": "whS_PuwYSAbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_image = torchvision.io.read_image(str(custom_image_path)).type(torch.float32)\n",
        "\n",
        "custom_image = custom_image / 255.\n",
        "\n",
        "# Print out image data\n",
        "print(f\"Custom image tensor:\\n{custom_image}\\n\")\n",
        "print(f\"Custom image shape: {custom_image.shape}\\n\")\n",
        "print(f\"Custom image dtype: {custom_image.dtype}\")"
      ],
      "metadata": {
        "id": "snMjfW22URhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(custom_image.permute(1, 2, 0))\n",
        "plt.title(f\"Image shape: {custom_image.shape}\")\n",
        "plt.axis(False);"
      ],
      "metadata": {
        "id": "UL7WRQ2SUoLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create transform pipleine to resize image\n",
        "custom_image_transform = transforms.Compose([transforms.Resize((64, 64))])\n",
        "\n",
        "custom_image_transformed = custom_image_transform(custom_image)\n",
        "\n",
        "print(f\"Original shape: {custom_image.shape}\")\n",
        "print(f\"New shape: {custom_image_transformed.shape}\")"
      ],
      "metadata": {
        "id": "IHnf4-zHU4bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.eval()\n",
        "with torch.inference_mode():\n",
        "  custom_image_pred = model_1(custom_image_transformed.unsqueeze(dim=0).to(device))\n",
        "custom_image_pred"
      ],
      "metadata": {
        "id": "yfU-c9SMV7TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert logits\n",
        "custom_image_pred_probs = torch.softmax(custom_image_pred, dim=1)\n",
        "custom_image_pred_probs"
      ],
      "metadata": {
        "id": "0z94H9UhWhpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_image_pred_labels = torch.argmax(custom_image_pred_probs, dim=1)\n",
        "custom_image_pred_labels"
      ],
      "metadata": {
        "id": "HYlG0dGVXArA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names[custom_image_pred_labels]"
      ],
      "metadata": {
        "id": "eSuPic8-XD9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# putting together\n",
        "def pred_plot_image(model: torch.nn.Module, image_path: str, class_names: List[str], transform: torchvision.transforms=None, device: torch.device=device):\n",
        "  target_image = torchvision.io.read_image(str(image_path)).type(torch.float32)\n",
        "  target_image = target_image / 255.\n",
        "\n",
        "  if transform:\n",
        "    target_image = transform(target_image)\n",
        "  model.to(device)\n",
        "\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    target_image = target_image.unsqueeze(0)\n",
        "    target_image_pred = model(target_image.to(device))\n",
        "  target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n",
        "  target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)\n",
        "\n",
        "  #plotting\n",
        "\n",
        "  plt.imshow(target_image.squeeze().permute(1,2,0))\n",
        "  if class_names:\n",
        "    title = f\"Pred: {class_names[target_image_pred_label.cpu()]} | Prob: {target_image_pred_probs.max().cpu():.3f}\"\n",
        "  else:\n",
        "    title = f\"Pred: {target_image_pred_label} | Prob: {target_image_pred_probs.max().cpu():.3f}\"\n",
        "  plt.title(title)\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "yeCjwvf1XJx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_plot_image(model=model_1, image_path=custom_image_path, class_names=class_names, transform=custom_image_transform, device=device)"
      ],
      "metadata": {
        "id": "qe_nUBO3YgOO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}