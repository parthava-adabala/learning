{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPr6iJiN5Ly/5n2iMLUaO8f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parthava-adabala/learning/blob/main/03_Pytorch_ComputerVision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeIzY1g440q_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.__version__, torchvision.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get dataset"
      ],
      "metadata": {
        "id": "elIEYA_iA3Ux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.FashionMNIST(root='data', train=True, download=True, transform=ToTensor(), target_transform=None)\n",
        "test_data = datasets.FashionMNIST(root='data', train=False, download=True, transform=ToTensor(), target_transform=None)"
      ],
      "metadata": {
        "id": "ndLxlol1BOBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "QprBPgBHChKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[0]\n",
        "image, label"
      ],
      "metadata": {
        "id": "GUuDP9FHCrTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape, label"
      ],
      "metadata": {
        "id": "X0MCGOaYDwoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = train_data.classes\n",
        "classes"
      ],
      "metadata": {
        "id": "gfSu1xT2CuOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_to_idx = train_data.class_to_idx\n",
        "class_to_idx"
      ],
      "metadata": {
        "id": "l6bPyE8oDE06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets = train_data.targets\n",
        "targets"
      ],
      "metadata": {
        "id": "qmOTTudSDKH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image.squeeze())\n",
        "plt.title(classes[label])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yBk7XV7KDYfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image.squeeze(), cmap='gray')\n",
        "plt.title(classes[label])\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mdb01wFgEjJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's plot more images\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(25):\n",
        "    ax = plt.subplot(5, 5, i + 1)\n",
        "    image, label = train_data[i]\n",
        "    plt.imshow(image.squeeze(), cmap='gray', aspect='auto')\n",
        "    plt.title(classes[label])\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4c79mNwGEshI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#prepare data loader"
      ],
      "metadata": {
        "id": "bAog4MfmFCR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "ZU3RvFp3GgXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader.batch_size, len(train_dataloader)"
      ],
      "metadata": {
        "id": "GWZBVs0jH08T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
        "train_features_batch.shape, train_labels_batch.shape"
      ],
      "metadata": {
        "id": "nNZ3ViHdW338"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sample\n",
        "torch.manual_seed(42)\n",
        "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
        "image, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
        "plt.imshow(image.squeeze(), cmap='gray', aspect='auto')\n",
        "plt.title(classes[label])\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dtSDinZOWBPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline model"
      ],
      "metadata": {
        "id": "WtZy4pN0WSaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# flatten layer\n",
        "flatten = torch.nn.Flatten()\n",
        "x = train_features_batch[0]\n",
        "out = flatten(x)\n",
        "x.shape, out.shape"
      ],
      "metadata": {
        "id": "pvDhu1ONYROX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out.squeeze()"
      ],
      "metadata": {
        "id": "iFLj_yfHY7Ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMNISTV0(torch.nn.Module):\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.layer_stack = torch.nn.Sequential(\n",
        "            torch.nn.Flatten(),\n",
        "            torch.nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "            torch.nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        return self.layer_stack(x)"
      ],
      "metadata": {
        "id": "C-iAIA8hZR1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model_0 = FashionMNISTV0(input_shape=784, hidden_units=10, output_shape=len(classes))\n",
        "model_0"
      ],
      "metadata": {
        "id": "Jy6w_rReaRbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_x = torch.rand([1, 1, 28, 28])\n",
        "model_0(dummy_x)"
      ],
      "metadata": {
        "id": "49nWni3yHu7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "if Path('helper_functions.py').is_file():\n",
        "    print('helper_functions.py already exists')\n",
        "else:\n",
        "    print('Downloading helper_functions.py')\n",
        "    request = requests.get('https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py')\n",
        "    with open('helper_functions.py', 'wb') as f:\n",
        "        f.write(request.content)"
      ],
      "metadata": {
        "id": "ukW4CoHlJpov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function and optimizer and eval metric\n",
        "from helper_functions import accuracy_fn\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)\n"
      ],
      "metadata": {
        "id": "AJy-rdpqICR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "def print_train_time(start: float, end: float, device: torch.device = None):\n",
        "    total_time = end - start\n",
        "    print(f'Train time on {device}: {total_time:.3f} seconds')\n",
        "    return total_time"
      ],
      "metadata": {
        "id": "KTpzTLppKOOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = timer()\n",
        "#some code\n",
        "end_time = timer()\n",
        "print_train_time(start=start_time, end=end_time, device=\"cpu\")"
      ],
      "metadata": {
        "id": "bnVB2s1OKwsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "torch.manual_seed(42)\n",
        "train_time_start_on_cpu = timer()\n",
        "\n",
        "epochs = 3\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  train_loss = 0\n",
        "  for batch, (X, y) in enumerate(train_dataloader):\n",
        "    model_0.train()\n",
        "    y_pred = model_0(X)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss.item()\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch % 400 == 0:\n",
        "      print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
        "  train_loss /= len(train_dataloader)\n",
        "  test_loss, test_acc = 0, 0\n",
        "  model_0.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X_test, y_test in test_dataloader:\n",
        "      test_pred = model_0(X_test)\n",
        "      test_loss += loss_fn(test_pred, y_test)\n",
        "      test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n",
        "    test_loss /= len(test_dataloader)\n",
        "    test_acc /= len(test_dataloader)\n",
        "  print(f\"Train loss: {train_loss:.5f} | Test loss: {test_loss:.5f} | Test acc: {test_acc:.2f}%\")\n",
        "train_time_end_on_cpu = timer()\n",
        "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu, end=train_time_end_on_cpu, device=str(next(model_0.parameters()).device))\n",
        "total_train_time_model_0"
      ],
      "metadata": {
        "id": "ZPi7ppXNLHKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make preds\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # Define device here\n",
        "def eval_model(model: torch.nn.Module, data_loader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module, accuracy_fn, device=device):\n",
        "  loss, acc = 0, 0\n",
        "  model.eval()\n",
        "  model.to(device) # Move the model to the target device\n",
        "  with torch.inference_mode():\n",
        "    for X, y in tqdm(data_loader):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      y_pred = model(X).to(device) # Move prediction to the device\n",
        "      loss += loss_fn(y_pred, y)\n",
        "      acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
        "    loss /= len(data_loader)\n",
        "    acc /= len(data_loader)\n",
        "  return {\"model_name\": model.__class__.__name__, \"model_loss\": loss.item(), \"model_acc\": acc}\n",
        "\n",
        "model_0_results = eval_model(model=model_0, data_loader=test_dataloader, loss_fn=loss_fn, accuracy_fn=accuracy_fn)\n",
        "model_0_results"
      ],
      "metadata": {
        "id": "gl79eZPsOq06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#device agnostic code"
      ],
      "metadata": {
        "id": "bhhtyjvMRhon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "2l5PQb3yR8LM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "KcNJo8xBR9h7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "yq1O5FTOSDgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1 with non linearity\n",
        "class FashionMNISTV1(torch.nn.Module):\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "        super().__init__()\n",
        "        self.layer_stack = torch.nn.Sequential(\n",
        "            torch.nn.Flatten(),\n",
        "            torch.nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
        "            torch.nn.ReLU()\n",
        "            )\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        return self.layer_stack(x)"
      ],
      "metadata": {
        "id": "5JlreYk5SWYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create model instance\n",
        "torch.manual_seed(42)\n",
        "model_1 = FashionMNISTV1(input_shape=784, hidden_units=10, output_shape=len(classes)).to(device)"
      ],
      "metadata": {
        "id": "hI5nmnKxTUyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import accuracy_fn\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_1.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "BCzlDhW5ToYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functionizing train test loops"
      ],
      "metadata": {
        "id": "clXgoDZZUAKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model: torch.nn.Module, data_loader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module, optimizer: torch.optim.Optimizer, accuracy_fn, device: torch.device = device):\n",
        "  train_loss, train_acc = 0, 0\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(data_loader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    y_pred = model(X)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss\n",
        "    train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  train_loss /= len(data_loader)\n",
        "  train_acc /= len(data_loader)\n",
        "  print(f\"train_loss:{train_loss:.5f}, train_acc:{train_acc:.2f}%\")"
      ],
      "metadata": {
        "id": "iK2EgwUEUOz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model: torch.nn.Module, data_loader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module, accuracy_fn, device: torch.device = device):\n",
        "  test_loss, test_acc = 0, 0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X, y in data_loader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      test_pred = model(X)\n",
        "      test_loss += loss_fn(test_pred, y)\n",
        "      test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
        "    test_loss /= len(data_loader)\n",
        "    test_acc /= len(data_loader)\n",
        "    print(f\"test_loss:{test_loss:.5f}, test_acc:{test_acc:.2f}%\")"
      ],
      "metadata": {
        "id": "XW8OrOs9Vkxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# measure time\n",
        "from timeit import default_timer as timer\n",
        "train_time_start_on_gpu = timer()\n",
        "\n",
        "epochs = 3\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n-------\")\n",
        "  train_step(model=model_1, data_loader=train_dataloader, loss_fn=loss_fn, optimizer=optimizer, accuracy_fn=accuracy_fn, device = device)\n",
        "  test_step(model=model_1, data_loader=test_dataloader, loss_fn=loss_fn, accuracy_fn=accuracy_fn, device = device)\n",
        "train_time_end_on_gpu = timer()\n",
        "total_train_time_model_1 = print_train_time(start=train_time_start_on_gpu, end=train_time_end_on_gpu, device=str(next(model_1.parameters()).device))"
      ],
      "metadata": {
        "id": "nyYMJA4RXuKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results = eval_model(model=model_1, data_loader=test_dataloader, loss_fn=loss_fn, accuracy_fn=accuracy_fn, device=device)\n",
        "model_1_results"
      ],
      "metadata": {
        "id": "5a2fe_NPZV-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 2 with CNN"
      ],
      "metadata": {
        "id": "56jMCas7aYLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMNISTV2(torch.nn.Module):\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.conv_block_2 = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.classifier = torch.nn.Sequential(\n",
        "        torch.nn.Flatten(),\n",
        "        torch.nn.Linear(in_features=hidden_units*7*7, out_features=output_shape))\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    x = self.conv_block_1(x)\n",
        "    #print(x.shape)\n",
        "    x = self.conv_block_2(x)\n",
        "    #print(x.shape)\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "0rjet7mrcOHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model_2 = FashionMNISTV2(input_shape=1, hidden_units=10, output_shape=len(classes)).to(device)\n",
        "model_2"
      ],
      "metadata": {
        "id": "7XG93nb5fY-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stepping through nn.Conv2d"
      ],
      "metadata": {
        "id": "n34x6S8WfsGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# create a batch of images\n",
        "images = torch.randn(size=(32, 3, 64, 64))\n",
        "test_image = images[0]\n",
        "images.shape, test_image.shape, images"
      ],
      "metadata": {
        "id": "v7oGLt9egQfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a single conv2d layer\n",
        "torch.manual_seed(42)\n",
        "conv_layer = torch.nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(3,3), stride=1, padding=1)\n",
        "conv_out = conv_layer(test_image.unsqueeze(dim=0))\n",
        "conv_out.shape, conv_out"
      ],
      "metadata": {
        "id": "7dVWp8ShgyZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stepping through Maxpool2d"
      ],
      "metadata": {
        "id": "DnBMuUS1iKF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_image.shape"
      ],
      "metadata": {
        "id": "cced0weejWAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_pool_layer = torch.nn.MaxPool2d(kernel_size=2)\n",
        "max_pool_out = max_pool_layer(test_image.unsqueeze(dim=0))\n",
        "max_pool_out.shape, max_pool_out"
      ],
      "metadata": {
        "id": "UEKc5PG6mnRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# set up loss function and optimizer"
      ],
      "metadata": {
        "id": "PsckHIyRnApu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import accuracy_fn\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_2.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "YTfuXOuOqf57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.state_dict()"
      ],
      "metadata": {
        "id": "ka5oUP5KqmsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "#measure time\n",
        "from timeit import default_timer as timer\n",
        "train_time_start_model_2 = timer()\n",
        "\n",
        "epochs = 3\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n-------\")\n",
        "  train_step(model=model_2, data_loader=train_dataloader, loss_fn=loss_fn, optimizer=optimizer, accuracy_fn=accuracy_fn, device = device)\n",
        "  test_step(model=model_2, data_loader=test_dataloader, loss_fn=loss_fn, accuracy_fn=accuracy_fn, device = device)\n",
        "train_time_end_model_2 = timer()\n",
        "total_train_time_model_2 = print_train_time(start=train_time_start_model_2, end=train_time_end_model_2, device=str(next(model_2.parameters()).device))"
      ],
      "metadata": {
        "id": "xMQw3IydqqSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results = eval_model(model=model_2, data_loader=test_dataloader, loss_fn=loss_fn, accuracy_fn=accuracy_fn, device=device)\n",
        "model_2_results"
      ],
      "metadata": {
        "id": "_oN_k1_hrNG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare model results and training time"
      ],
      "metadata": {
        "id": "TVRkuBhMrrV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "compare_results = pd.DataFrame([model_0_results, model_1_results, model_2_results])\n",
        "compare_results"
      ],
      "metadata": {
        "id": "R1INiuBDr64r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_results[\"training time (s)\"] = [total_train_time_model_0, total_train_time_model_1, total_train_time_model_2]\n",
        "compare_results"
      ],
      "metadata": {
        "id": "DLp92PWvsNbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize\n",
        "compare_results.set_index('model_name')['model_acc'].plot(kind='barh')\n",
        "plt.xlabel('Accuracy (%)')\n",
        "plt.ylabel('Model')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gSYLSD6Bsnna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make and evaluate randpm predictions with our best model\n",
        "def make_predictions(model: torch.nn.Module, data: list, device: torch.device = device):\n",
        "  pred_probs = []\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for sample in data:\n",
        "      sample = torch.unsqueeze(sample, dim=0).to(device)\n",
        "      pred_logit = model(sample.to(device))\n",
        "      pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)\n",
        "      pred_probs.append(pred_prob.cpu())\n",
        "  return torch.stack(pred_probs)"
      ],
      "metadata": {
        "id": "rK33rQunyVzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "test_samples = []\n",
        "test_labels = []\n",
        "for sample, label in random.sample(list(test_data), k=9):\n",
        "  test_samples.append(sample)\n",
        "  test_labels.append(label)\n",
        "test_samples[0].shape"
      ],
      "metadata": {
        "id": "yiQv8T67zYMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_samples[0].squeeze(), cmap='gray')\n",
        "plt.title(classes[test_labels[0]])"
      ],
      "metadata": {
        "id": "kExC51t1z25c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "pred_probs = make_predictions(model=model_2, data=test_samples)\n",
        "pred_probs[:2]"
      ],
      "metadata": {
        "id": "7Txg0rJo0GWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_classes = torch.argmax(pred_probs, dim=1)\n",
        "pred_classes"
      ],
      "metadata": {
        "id": "wSp3HvsV0Oj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot predictions\n",
        "plt.figure(figsize=(9, 9))\n",
        "nrows, ncols = 3, 3\n",
        "for i, image in enumerate(test_samples):\n",
        "  plt.subplot(nrows, ncols, i+1)\n",
        "  plt.imshow(image.squeeze(), cmap='gray')\n",
        "  pred_label = classes[pred_classes[i]]\n",
        "  true_label = classes[test_labels[i]]\n",
        "  title_text = f\"Pred: {pred_label} | True: {true_label}\"\n",
        "  if pred_label == true_label:\n",
        "    plt.title(title_text, fontsize=10, c='g')\n",
        "  else:\n",
        "    plt.title(title_text, fontsize=10, c='r')\n",
        "  plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NnXckXx20eZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = []\n",
        "model_2.eval()\n",
        "with torch.inference_mode():\n",
        "  for X, y in tqdm(test_dataloader, desc=\"Making predictions\"):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    y_logit = model_2(X)\n",
        "    y_pred = torch.softmax(y_logit.squeeze(), dim=0).argmax(dim=1)\n",
        "    y_preds.append(y_pred.cpu())\n",
        "# print(y_preds)\n",
        "y_pred_tensor = torch.cat(y_preds)\n",
        "y_pred_tensor[:10]\n"
      ],
      "metadata": {
        "id": "h200zVrq01gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_pred_tensor)"
      ],
      "metadata": {
        "id": "uGXr7wYa2qzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# make a confusion matrix"
      ],
      "metadata": {
        "id": "IsSkuoMH19uD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import torchmetrics, mlxtend\n",
        "  assert int(mlxtend.__version__.split(\".\")[1]>=19)\n",
        "except:\n",
        "  !pip install -q torchmetrics mlxtend\n",
        "  import torchmetrics, mlxtend"
      ],
      "metadata": {
        "id": "9IWLNsDR2MX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import ConfusionMatrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "confmat = ConfusionMatrix(num_classes=len(classes), task=\"multiclass\")\n",
        "confmat_tensor = confmat(y_pred_tensor, test_data.targets)\n",
        "confmat_tensor"
      ],
      "metadata": {
        "id": "Dx5GuIdK3kbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plot_confusion_matrix(conf_mat=confmat_tensor.numpy(), figsize=(8, 8), class_names=classes)\n",
        "plt.title(\"Confusion Matrix\")"
      ],
      "metadata": {
        "id": "MePv-uNS4cyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving model"
      ],
      "metadata": {
        "id": "pKttf3Ps45DA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "MODEL_NAME = \"fashion_mnist_cnn_model_v2.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "MODEL_SAVE_PATH"
      ],
      "metadata": {
        "id": "Xnh8y98o5W42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(obj=model_2.state_dict(), f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "z3oJP_vh53oE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_2 = FashionMNISTV2(input_shape=1, hidden_units=10, output_shape=len(classes))\n",
        "loaded_model_2.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
        "loaded_model_2.to(device)"
      ],
      "metadata": {
        "id": "wfDk3vuE6CVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results"
      ],
      "metadata": {
        "id": "LVIKZIg16Un0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_2_results = eval_model(model=loaded_model_2, data_loader=test_dataloader, loss_fn=loss_fn, accuracy_fn=accuracy_fn)\n",
        "loaded_model_2_results"
      ],
      "metadata": {
        "id": "xpHP4lZ26ghg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the model results are close\n",
        "torch.isclose(torch.tensor(model_2_results['model_loss']), torch.tensor(loaded_model_2_results['model_loss']), atol=1e-02)"
      ],
      "metadata": {
        "id": "3ZK1DNNQ6y71"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}